spring:
  datasource:
    username:
    password:

  kafka:
    bootstrap-servers: dev-cluster-kafka-bootstrap-dev-kafka.apps.dev.sbiepay.sbi:443
    properties:
      #Spring-Kafka SSL Configuration for local
      security.protocol: SSL
      ssl:
        truststore:
          location: C:/certs/kafka/dev-cluster-cluster-ca-cert.p12
          password: Xe8FrxOGvVAx
          type: PKCS12
        keystore:
          location: C:/certs/kafka/dev-cluster-clients-ca-cert.p12
          password: J55FITkgEFid
          type: PKCS12
    consumer:
      number-of-consumer: 1
    topic:
        partitions: 4
        replication-factor: 1

---------------

spring:
  datasource:
    username: PAYAGGREPORT
    password:

  kafka:
    bootstrap-servers: dev-cluster-kafka-bootstrap-dev-kafka.apps.dev.sbiepay.sbi:443
_----------------------------------------------

spring.datasource.username=
spring.datasource.password=

spring.kafka.bootstrap-servers=dev-cluster-kafka-bootstrap-dev-kafka.apps.dev.sbiepay.sbi:443

# Spring-Kafka SSL Configuration
spring.kafka.properties.security.protocol=SSL
spring.kafka.properties.ssl.truststore.location=C:/certs/kafka/dev-cluster-cluster-ca-cert.p12
spring.kafka.properties.ssl.truststore.password=Xe8FrxOGvVAx
spring.kafka.properties.ssl.truststore.type=PKCS12
spring.kafka.properties.ssl.keystore.location=C:/certs/kafka/dev-cluster-clients-ca-cert.p12
spring.kafka.properties.ssl.keystore.password=J55FITkgEFid
spring.kafka.properties.ssl.keystore.type=PKCS12

spring.kafka.consumer.number-of-consumer=1
spring.kafka.topic.partitions=4
spring.kafka.topic.replication-factor=1
---------------------------------------

spring.datasource.username=PAYAGGREPORT
spring.datasource.password=
spring.kafka.bootstrap-servers=dev-cluster-kafka-bootstrap-dev-kafka.apps.dev.sbiepay.sbi:443

---------------------------------------------------------------------------------------------------------------

package com.epay.merchant.config.kafka;

import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.config.KafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
import org.springframework.kafka.listener.ConcurrentMessageListenerContainer;
import org.springframework.kafka.support.serializer.JsonDeserializer;

import java.util.HashMap;
import java.util.Map;

@Configuration
public class KafkaConsumerConfig {

    public Map<String, Object> consumerConfigs(KafkaConsumerSettings kafkaConsumerSettings) {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaConsumerSettings.getBootstrapServers());
        props.put(ConsumerConfig.GROUP_ID_CONFIG, kafkaConsumerSettings.getGroupId());
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, kafkaConsumerSettings.isAutoCommitCursor());
        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, kafkaConsumerSettings.getAutoCommitCursorIntervalMS());
        props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, kafkaConsumerSettings.getSessionTimeoutMS());
        props.put(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG, kafkaConsumerSettings.getRequestTimeoutMS());
        props.put(ConsumerConfig.FETCH_MAX_WAIT_MS_CONFIG, kafkaConsumerSettings.getFetchMaxWaitMS());
        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, kafkaConsumerSettings.getMaxPollRecords());
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, kafkaConsumerSettings.getOffsetReset());
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, kafkaConsumerSettings.getKeyDeserializer());
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, kafkaConsumerSettings.getValueDeserializer());
        return props;
    }

    public ConsumerFactory<String, Object> consumerFactory(KafkaConsumerSettings kafkaConsumerSettings) {
        return new DefaultKafkaConsumerFactory<>(consumerConfigs(kafkaConsumerSettings));
    }

    public KafkaListenerContainerFactory<ConcurrentMessageListenerContainer<String, Object>> kafkaListenerContainerFactory(KafkaConsumerSettings kafkaConsumerSettings) {
        ConcurrentKafkaListenerContainerFactory<String, Object> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(consumerFactory(kafkaConsumerSettings));
        factory.setConcurrency(kafkaConsumerSettings.getNumberOfConsumers());
        return factory;
    }
}
---------------------------------------

package com.epay.merchant.etl.listener;

import com.epay.merchant.exception.MerchantException;
import com.fasterxml.jackson.databind.ObjectMapper;
import com.sbi.epay.logging.utility.LoggerFactoryUtility;
import com.sbi.epay.logging.utility.LoggerUtility;
import com.sbi.epay.notification.model.EmailDto;
import com.sbi.epay.notification.model.SmsDto;
import com.sbi.epay.notification.service.EmailService;
import com.sbi.epay.notification.service.SmsService;
import lombok.RequiredArgsConstructor;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.springframework.kafka.annotation.KafkaListener;
import org.springframework.stereotype.Component;

@Component
@RequiredArgsConstructor
public class SendNotificationListener {
    private final LoggerUtility log = LoggerFactoryUtility.getLogger(this.getClass());
    private final SmsService smsService;
    private final EmailService emailService;
    private final ObjectMapper objectMapper;

    @KafkaListener(topics = "${spring.kafka.topic.merchant.notification.email}")
    public void onEmailMessage(ConsumerRecord<String, Object> consumerRecord) {
        log.debug("Send email notification request received for key : {} and value : {}", consumerRecord.key(), consumerRecord.value());
        try {
            Object s = consumerRecord.value();
//            emailService.sendEmail(consumerRecord.value());
        } catch (MerchantException e) {
            log.error("Error during onEmailMessage kafka listening message[key:{} and value: {}], error: {}", consumerRecord.key(), consumerRecord.value(), e.getErrorMessage());
        } catch (Exception e) {
            log.error("Error during onEmailMessage kafka listening message[key:{} and value: {}], error: {}", consumerRecord.key(), consumerRecord.value(), e.getMessage());
        }

    }
}
-----------------------------------------------------------------------------

package com.epay.merchant.config.kafka;

import com.epay.merchant.config.kafka.env.local.KafkaProducerLocalSettings;
import com.sbi.epay.logging.utility.LoggerFactoryUtility;
import com.sbi.epay.logging.utility.LoggerUtility;
import lombok.RequiredArgsConstructor;
import org.apache.kafka.clients.CommonClientConfigs;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.config.SslConfigs;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;

import java.net.InetAddress;
import java.net.UnknownHostException;
import java.util.HashMap;
import java.util.Map;

/**
 * Class Name: KafkaProducerConfig
 * *
 * Description: This is parent for kafka config class.
 * *
 * Author: Bhoopendra Rajput
 * <p>
 * Copyright (c) 2024 [State Bank of India]
 * All rights reserved
 * *
 * Version:1.0
 */
@Configuration
@RequiredArgsConstructor
public class KafkaProducerConfig {
    private final LoggerUtility log = LoggerFactoryUtility.getLogger(this.getClass());
    private final KafkaProducerSettings kafkaProducerSettings;

    @Bean
    public KafkaTemplate<String, String> kafkaTemplate() {
        return new KafkaTemplate<>(producerFactory());
    }

    private ProducerFactory<String, String> producerFactory() {
        return new DefaultKafkaProducerFactory<>(producerConfigs());
    }

    private Map<String, Object> producerConfigs() {
        Map<String, Object> props = new HashMap<>();

        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProducerSettings.getBootstrapServers());
        props.put(ProducerConfig.ACKS_CONFIG, kafkaProducerSettings.getAcks());
        props.put(ProducerConfig.RETRIES_CONFIG, kafkaProducerSettings.getRetries());
        props.put(ProducerConfig.BATCH_SIZE_CONFIG, kafkaProducerSettings.getBatchSize());
        props.put(ProducerConfig.LINGER_MS_CONFIG, kafkaProducerSettings.getLingerMs());
        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, kafkaProducerSettings.getBufferMemory());
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        if ("local".equalsIgnoreCase(kafkaProducerSettings.getActiveProfile())) {
            KafkaProducerLocalSettings kafkaProducerLocalSettings = (KafkaProducerLocalSettings) kafkaProducerSettings;
            props.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, kafkaProducerLocalSettings.getSecurityProtocol());
            props.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, kafkaProducerLocalSettings.getTrustLocation());
            props.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, kafkaProducerLocalSettings.getTrustPassword());
            props.put(SslConfigs.SSL_TRUSTSTORE_TYPE_CONFIG, kafkaProducerLocalSettings.getTrustType());
            props.put(SslConfigs.SSL_KEYSTORE_LOCATION_CONFIG, kafkaProducerLocalSettings.getKeyLocation());
            props.put(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG, kafkaProducerLocalSettings.getKeyPassword());
            props.put(SslConfigs.SSL_KEYSTORE_TYPE_CONFIG, kafkaProducerLocalSettings.getKeyType());
        }
        try {
            props.put(ProducerConfig.CLIENT_ID_CONFIG, InetAddress.getLocalHost().getHostName());
        } catch (UnknownHostException e) {
            log.error("Error in producerConfigs : {}", e.getMessage());
        }

        return props;
    }
}
-------------------------------------------------


package com.epay.merchant.config.kafka;

import com.epay.merchant.config.kafka.env.local.KafkaProducerLocalSettings;
import com.sbi.epay.logging.utility.LoggerFactoryUtility;
import com.sbi.epay.logging.utility.LoggerUtility;
import lombok.RequiredArgsConstructor;
import org.apache.kafka.clients.CommonClientConfigs;
import org.apache.kafka.clients.producer.ProducerConfig;
import org.apache.kafka.common.config.SslConfigs;
import org.apache.kafka.common.serialization.ByteArraySerializer;
import org.apache.kafka.common.serialization.StringSerializer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.core.DefaultKafkaProducerFactory;
import org.springframework.kafka.core.KafkaTemplate;
import org.springframework.kafka.core.ProducerFactory;

import java.net.InetAddress;
import java.net.UnknownHostException;
import java.util.HashMap;
import java.util.Map;

@Configuration
@RequiredArgsConstructor
public class KafkaProducerConfig {
    private final LoggerUtility log = LoggerFactoryUtility.getLogger(this.getClass());
    private final KafkaProducerSettings kafkaProducerSettings;

    @Bean
    public KafkaTemplate<String, String> stringKafkaTemplate() {
        return new KafkaTemplate<>(stringProducerFactory());
    }

    @Bean
    public KafkaTemplate<String, byte[]> byteArrayKafkaTemplate() {
        return new KafkaTemplate<>(byteArrayProducerFactory());
    }

    private ProducerFactory<String, String> stringProducerFactory() {
        return new DefaultKafkaProducerFactory<>(producerConfigs(StringSerializer.class));
    }

    private ProducerFactory<String, byte[]> byteArrayProducerFactory() {
        return new DefaultKafkaProducerFactory<>(producerConfigs(ByteArraySerializer.class));
    }

    private Map<String, Object> producerConfigs(Class<?> valueSerializerClass) {
        Map<String, Object> props = new HashMap<>();

        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaProducerSettings.getBootstrapServers());
        props.put(ProducerConfig.ACKS_CONFIG, kafkaProducerSettings.getAcks());
        props.put(ProducerConfig.RETRIES_CONFIG, kafkaProducerSettings.getRetries());
        props.put(ProducerConfig.BATCH_SIZE_CONFIG, kafkaProducerSettings.getBatchSize());
        props.put(ProducerConfig.LINGER_MS_CONFIG, kafkaProducerSettings.getLingerMs());
        props.put(ProducerConfig.BUFFER_MEMORY_CONFIG, kafkaProducerSettings.getBufferMemory());
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, valueSerializerClass);

        if ("local".equalsIgnoreCase(kafkaProducerSettings.getActiveProfile())) {
            KafkaProducerLocalSettings kafkaProducerLocalSettings = (KafkaProducerLocalSettings) kafkaProducerSettings;
            props.put(CommonClientConfigs.SECURITY_PROTOCOL_CONFIG, kafkaProducerLocalSettings.getSecurityProtocol());
            props.put(SslConfigs.SSL_TRUSTSTORE_LOCATION_CONFIG, kafkaProducerLocalSettings.getTrustLocation());
            props.put(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, kafkaProducerLocalSettings.getTrustPassword());
            props.put(SslConfigs.SSL_TRUSTSTORE_TYPE_CONFIG, kafkaProducerLocalSettings.getTrustType());
            props.put(SslConfigs.SSL_KEYSTORE_LOCATION_CONFIG, kafkaProducerLocalSettings.getKeyLocation());
            props.put(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG, kafkaProducerLocalSettings.getKeyPassword());
            props.put(SslConfigs.SSL_KEYSTORE_TYPE_CONFIG, kafkaProducerLocalSettings.getKeyType());
        }
        try {
            props.put(ProducerConfig.CLIENT_ID_CONFIG, InetAddress.getLocalHost().getHostName());
        } catch (UnknownHostException e) {
            log.error("Error in producerConfigs : {}", e.getMessage());
        }

        return props;
    }
}
---------------------------------------------

package com.epay.merchant.config.kafka;

import com.sbi.epay.logging.utility.LoggerFactoryUtility;
import com.sbi.epay.logging.utility.LoggerUtility;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.ByteArrayDeserializer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
import org.springframework.kafka.core.ConsumerFactory;
import org.springframework.kafka.core.DefaultKafkaConsumerFactory;

import java.util.HashMap;
import java.util.Map;

@Configuration
public class KafkaConsumerConfig {
    private final LoggerUtility log = LoggerFactoryUtility.getLogger(this.getClass());
    private final KafkaConsumerSettings kafkaConsumerSettings;

    public KafkaConsumerConfig(KafkaConsumerSettings kafkaConsumerSettings) {
        this.kafkaConsumerSettings = kafkaConsumerSettings;
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, String> stringKafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, String> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(stringConsumerFactory());
        factory.setConcurrency(kafkaConsumerSettings.getNumberOfConsumers());
        return factory;
    }

    @Bean
    public ConcurrentKafkaListenerContainerFactory<String, byte[]> byteArrayKafkaListenerContainerFactory() {
        ConcurrentKafkaListenerContainerFactory<String, byte[]> factory = new ConcurrentKafkaListenerContainerFactory<>();
        factory.setConsumerFactory(byteArrayConsumerFactory());
        factory.setConcurrency(kafkaConsumerSettings.getNumberOfConsumers());
        return factory;
    }

    private ConsumerFactory<String, String> stringConsumerFactory() {
        return new DefaultKafkaConsumerFactory<>(consumerConfigs(StringDeserializer.class));
    }

    private ConsumerFactory<String, byte[]> byteArrayConsumerFactory() {
        return new DefaultKafkaConsumerFactory<>(consumerConfigs(ByteArrayDeserializer.class));
    }

    private Map<String, Object> consumerConfigs(Class<?> valueDeserializerClass) {
        Map<String, Object> props = new HashMap<>();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaConsumerSettings.getBootstrapServers());
        props.put(ConsumerConfig.GROUP_ID_CONFIG, kafkaConsumerSettings.getGroupId());
        props.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, kafkaConsumerSettings.isAutoCommitCursor());
        props.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, kafkaConsumerSettings.getAutoCommitCursorIntervalMS());
        props.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, kafkaConsumerSettings.getSessionTimeoutMS());
        props.put(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG, kafkaConsumerSettings.getRequestTimeoutMS());
        props.put(ConsumerConfig.FETCH_MAX_WAIT_MS_CONFIG, kafkaConsumerSettings.getFetchMaxWaitMS());
        props.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, kafkaConsumerSettings.getMaxPollRecords());
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, kafkaConsumerSettings.getOffsetReset());
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, valueDeserializerClass);
        return props;
    }
}
---------------------------------------------

public class EmailMaskingUtil {

    public static String maskEmail(String email) {
        if (email == null || !email.contains("@")) {
            throw new IllegalArgumentException("Invalid email address");
        }

        String[] parts = email.split("@");
        String localPart = parts[0];
        String domainPart = parts[1];

        // Mask local part: Keep first and last character visible
        String maskedLocalPart = localPart.length() > 2
                ? localPart.charAt(0) + "****" + localPart.charAt(localPart.length() - 1)
                : localPart.charAt(0) + "*";

        // Mask domain part: Keep last 3 characters visible
        String maskedDomainPart = domainPart.length() > 3
                ? "****" + domainPart.substring(domainPart.length() - 3)
                : domainPart;

        return maskedLocalPart + "@" + maskedDomainPart;
    }

    public static void main(String[] args) {
        String email = "example@gmail.com";
        System.out.println(maskEmail(email)); // Output: e****e@****com
    }
}
